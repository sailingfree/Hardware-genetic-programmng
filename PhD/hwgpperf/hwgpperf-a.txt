An analysis of a hardware implementation of genetic programming using FPGAs and Handel-c

The work so far has concentrated on the implementation issues and clock speed of the implementation, and the performance of the system with respect to it's ability to solve GP problems has been put aside. Now that the raw throughput issues have been addressed it is time to look at how good the hardware implementation performs, and investigate and analyse the reasons for the performance. 

The implementation incorporates several simplifications that allowed it to be realized, but that now need investigation. Firstly, the crossover operator limited the program size by truncating programs that would exceed the fixed storage allocation. The effect of this decision is as yet unknown. Secondly, a decision was made to use a logical AND operator where the modulus operator is traditionally used. This was done because in Handel-C the use of the MOD operator causes very deep logic to be produced which severely limits the clock rate that can be achieved. Thirdly, the random number generator is implemented using a Logical Feedback Shift Register which has a known weakness when used to produce a sequence of numbers.

Performance of original implementation.
The measurement of GP performance is frequently performed using the method described in Koza [koza]. This is shown for the original implementation in figure x. This will be used as a baseline when looking at cnages to the original design.

Truncating Crossover operator
The hardware design uses a linear program representation with a fixed maximum size. The choice of a fixed maximum size was made to make the storage of programs in on-chip RAM and off-chip RAM simple. Handel-C does not support dynamic memory in the way that ISO-C and modern operating systems do. Consequently a method of limiting the program size during crossover was needed. The method chosen was to choose crossover points in two individuals and crossover the tail portions up to the maximum program size. This is illustrated in figure xxx. To investigate the effect of this, the size distribution of the programs was measured during a run, and is shown in figure xxx. The striking feature is the peak at the maximum program size limit. This means that the probability of sampling a maximal size program is XXX. This has had the effect of  making GP behave very much like a standard fixed length GA. 
An alternative method of ensuring that programs do not exceed the fixed limit is to choose crossover points that result in programs that are below the limit. This is the approach taken in lilgp [lilgp] and others. If the handel-c implementation is modified as described, then the program length distribution changes dramatically as shown in figure xxx. The GP performance curve is shown now in figure xx with the original for comparison.

Crossover point limit operator
The traditional way of choosing a crossover point x at random in a program of length l is to use x = rand() % l; where rand() is a function that returns an integer between 0 and a value greater than l. In Handel-c the use of the C modulus operator % generates very deep logic. Deep logic is undesirable since it causes long combinatorial logic delays which limits the potential clock speed of the design. For this reason the % operator was not used. However, its use may have an effect on the overall performance by imposing a bias on the crossover operator and the results of crossover. To quantify the effect the % operator was implemented and the experiments re-run. Figure xxx shows the program size distribution using the % operator in the crossover operator using the saturating crossover operator and figure XXX shows the effect of using % in the limiting crossover operator. Figure xxx shows the GP performance for the % opeartor compared to the & operator for the saturating crossover operator and figure xxx shows the GP performance using the % operator against the & operator and the original implementation.

Random Number Generator
The original implementation used a LFSR. This has been used by other workers when implementing algorithms in hardware [list of refs] An alternative that is frequently reported is the use of a cellular automata (CA) [list of refs]. This section investigates the characteristics of the LFSR, CA, and compares them to the standard linear congruential random number generator. 
Figure xxx shows a schematic of the LFSR. The random number is read from teh lowest n bits as required. The principle weakness of this type of RNG is that sequential values fail the PAIRS test. For any value vi selected there is a very strong probability that vi+1 can be predicted. This is shown in figure xxx where pairs of values vi and vi+1 are plotted. Though the random number generator runs in parallel with the main GP machine, it is possible to access sequential values when creating an initial program , or when choosing crossover points. It is claimed that the CA is superior to the LFSR, so a simple 1 dimensional CA was also implemented and it's performance at the PAIRS test looked at . Figure XXX shows the result. Again there is a distinct  pattern to the numbers. This behaviour can also be seen by looking at the traditional CA patterns as generated by ZZZ. 
One method of obtaining better PAIRS test results for the LFSR of length n is to allow the LFSR to run for n cycles before reading another number. Another technique is  to implement n LFSRs and to use a single bit from each. This can also be done using a single long LFSR of n*m bits. Implementing this in a Xilinx Virtex FPGA though is not efficient because the look up table can implement a 16 bit shift register very easily, but longer shift registers require more extensive routing resources. 
The effect of using a better RNG was investigated by implementing 16 LFSR machines. The PAIRS test results are shown in figure XXX and the resulting GP performance in figures xxx-xxx. 


